{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a24a08db-4a58-42ad-a470-5b60b4d9b6fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Python interpreter will be restarted.\n",
       "Collecting nltk\n",
       "  Downloading nltk-3.5.zip (1.4 MB)\n",
       "Requirement already satisfied: joblib in /databricks/python3/lib/python3.7/site-packages (from nltk) (0.14.1)\n",
       "Collecting click\n",
       "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
       "Collecting regex\n",
       "  Downloading regex-2020.11.13-cp37-cp37m-manylinux2014_x86_64.whl (719 kB)\n",
       "Collecting tqdm\n",
       "  Downloading tqdm-4.54.1-py2.py3-none-any.whl (69 kB)\n",
       "Building wheels for collected packages: nltk\n",
       "  Building wheel for nltk (setup.py): started\n",
       "  Building wheel for nltk (setup.py): finished with status &#39;done&#39;\n",
       "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434675 sha256=72bf1a2acad6909f25a3d97f7c40d51579ab6702726eb7368833b7ab1ac480ed\n",
       "  Stored in directory: /root/.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266\n",
       "Successfully built nltk\n",
       "Installing collected packages: tqdm, regex, click, nltk\n",
       "Successfully installed click-7.1.2 nltk-3.5 regex-2020.11.13 tqdm-4.54.1\n",
       "Python interpreter will be restarted.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting nltk\n  Downloading nltk-3.5.zip (1.4 MB)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.7/site-packages (from nltk) (0.14.1)\nCollecting click\n  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\nCollecting regex\n  Downloading regex-2020.11.13-cp37-cp37m-manylinux2014_x86_64.whl (719 kB)\nCollecting tqdm\n  Downloading tqdm-4.54.1-py2.py3-none-any.whl (69 kB)\nBuilding wheels for collected packages: nltk\n  Building wheel for nltk (setup.py): started\n  Building wheel for nltk (setup.py): finished with status &#39;done&#39;\n  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434675 sha256=72bf1a2acad6909f25a3d97f7c40d51579ab6702726eb7368833b7ab1ac480ed\n  Stored in directory: /root/.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266\nSuccessfully built nltk\nInstalling collected packages: tqdm, regex, click, nltk\nSuccessfully installed click-7.1.2 nltk-3.5 regex-2020.11.13 tqdm-4.54.1\nPython interpreter will be restarted.\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f08e3385-51fa-43cd-8eae-a21aa39d6967",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Chandu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Chandu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.parse.corenlp import CoreNLPServer\n",
    "import os\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "java_path = \"C:/Program Files/Java/jdk1.8.0_271/bin/java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "STANFORD = os.path.join(\"models\", \"C:\\\\Users\\\\Chandu\\\\Downloads\\\\\")\n",
    "\n",
    "server = CoreNLPServer(\n",
    "   os.path.join(STANFORD, \"stanford-corenlp-3.9.1.jar\"),\n",
    "   os.path.join(STANFORD, \"stanford-corenlp-3.9.1-models.jar\"),    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the file and set it as a Dataframe. (1 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  sentiment\n",
      "0     Wow. Yall needa step it up @Apple RT @heynyla:...         -1\n",
      "1     What Happened To Apple Inc?   http://t.co/FJEX...          0\n",
      "2     Thank u @apple I can now compile all of the pi...          1\n",
      "3     The oddly uplifting story of the Apple co-foun...          0\n",
      "4     @apple can i exchange my iphone for a differen...          0\n",
      "...                                                 ...        ...\n",
      "1625     Those** PICK UP THE SLACK YOU FUCK BOYS @Apple         -1\n",
      "1626  Finally got my iPhone 6 in the mail and it com...         -1\n",
      "1627  @umo_games @Apple ended up getting a new compu...          0\n",
      "1628  The 19-Year-Old #WizKid Who Turned Down @Apple...          0\n",
      "1629  The iPhone 6 May Have A Longer Upgrade Cycle -...         -1\n",
      "\n",
      "[1630 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "pandas_df =pd.read_csv(\"C:\\\\Users\\\\Chandu\\\\Downloads\\\\archive\\\\apple-twitter-sentiment-texts.csv\")\n",
    "print(pandas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove punctuations, special characters and stopwords from the text column. Convert the text to lower case. (3 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "61745609-227b-455f-9666-7e0009d62faf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string.punctuation : !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "-----------------\n",
      "0       wow yall needa step it up apple rt heynyla mus...\n",
      "1       what happened to apple inc   httptcofjexi3op0u...\n",
      "2       thank u apple i can now compile all of the pic...\n",
      "3       the oddly uplifting story of the apple cofound...\n",
      "4       apple can i exchange my iphone for a different...\n",
      "                              ...                        \n",
      "1625          those pick up the slack you fuck boys apple\n",
      "1626    finally got my iphone 6 in the mail and it com...\n",
      "1627    umogames apple ended up getting a new computer...\n",
      "1628    the 19yearold wizkid who turned down apple has...\n",
      "1629    the iphone 6 may have a longer upgrade cycle  ...\n",
      "Name: review, Length: 1630, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(\"string.punctuation :\",string.punctuation)\n",
    "print(\"-----------------\")\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "        text = text.lower()\n",
    "    return text\n",
    "  \n",
    "pandas_df['review'] =  pandas_df['text'].apply(remove_punctuations)\n",
    "print(pandas_df['review'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create two objects X and y. X will be the 'Review' column dataframe and y will be the “Sentiment” column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d6f2a8fe-ec97-45f9-8fb4-1267c8a81b27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       wow yall needa step it up apple rt heynyla mus...\n",
      "1       what happened to apple inc   httptcofjexi3op0u...\n",
      "2       thank u apple i can now compile all of the pic...\n",
      "3       the oddly uplifting story of the apple cofound...\n",
      "4       apple can i exchange my iphone for a different...\n",
      "                              ...                        \n",
      "1625          those pick up the slack you fuck boys apple\n",
      "1626    finally got my iphone 6 in the mail and it com...\n",
      "1627    umogames apple ended up getting a new computer...\n",
      "1628    the 19yearold wizkid who turned down apple has...\n",
      "1629    the iphone 6 may have a longer upgrade cycle  ...\n",
      "Name: review, Length: 1630, dtype: object\n",
      "0      -1\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "1625   -1\n",
      "1626   -1\n",
      "1627    0\n",
      "1628    0\n",
      "1629   -1\n",
      "Name: sentiment, Length: 1630, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = pandas_df.review\n",
    "Y = pandas_df.sentiment\n",
    "#https://towardsdatascience.com/another-twitter-sentiment-analysis-bb5b01ebad90\n",
    "#https://towardsdatascience.com/twitter-sentiment-analysis-classification-using-nltk-python-fa912578614c\n",
    "#https://www.ritchieng.com/machine-learning-multinomial-naive-bayes-vectorization/\n",
    "#https://www.learndatasci.com/tutorials/predicting-reddit-news-sentiment-naive-bayes-text-classifiers/\n",
    "#https://www.kaggle.com/dyahnurlita/sentiment-analysis-using-multinomial-naive-bayes/notebook\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a CountVectorizer object and split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f9386749-54ad-46bc-be3e-2120ce7cc7ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoonova</th>\n",
       "      <th>zu</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuckerbergs</th>\n",
       "      <th>zum</th>\n",
       "      <th>鶯33000</th>\n",
       "      <th>鶯50</th>\n",
       "      <th>鶯500</th>\n",
       "      <th>鶯94986</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1630 rows × 5277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  03  04  05  07  08  09  10  100  1000  ...  zero  zoonova  zu  \\\n",
       "0      0   0   0   0   0   0   0   0    0     0  ...     0        0   0   \n",
       "1      0   0   0   0   0   0   0   0    0     0  ...     0        0   0   \n",
       "2      0   0   0   0   0   0   0   0    0     0  ...     0        0   0   \n",
       "3      0   0   0   0   0   0   0   0    0     0  ...     0        0   0   \n",
       "4      0   0   0   0   0   0   0   0    0     0  ...     0        0   0   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ...   ...  ...   ...      ...  ..   \n",
       "1625   0   0   0   0   0   0   0   0    0     0  ...     0        0   0   \n",
       "1626   0   0   0   0   0   0   0   0    0     0  ...     0        0   0   \n",
       "1627   0   0   0   0   0   0   0   0    0     0  ...     0        0   0   \n",
       "1628   0   0   0   0   0   0   0   0    0     0  ...     0        0   0   \n",
       "1629   0   0   0   0   0   0   0   0    0     0  ...     0        0   0   \n",
       "\n",
       "      zuckerberg  zuckerbergs  zum  鶯33000  鶯50  鶯500  鶯94986  \n",
       "0              0            0    0       0    0     0       0  \n",
       "1              0            0    0       0    0     0       0  \n",
       "2              0            0    0       0    0     0       0  \n",
       "3              0            0    0       0    0     0       0  \n",
       "4              0            0    0       0    0     0       0  \n",
       "...          ...          ...  ...     ...  ...   ...     ...  \n",
       "1625           0            0    0       0    0     0       0  \n",
       "1626           0            0    0       0    0     0       0  \n",
       "1627           0            0    0       0    0     0       0  \n",
       "1628           0            0    0       0    0     0       0  \n",
       "1629           0            0    0       0    0     0       0  \n",
       "\n",
       "[1630 rows x 5277 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X)\n",
    "vectorizer.get_feature_names()\n",
    "simple_train_dtm = vectorizer.transform(X)\n",
    "simple_train_dtm\n",
    "pd.DataFrame(simple_train_dtm.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b35a1422-26b0-4d33-969e-a8af6b951775",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=1)\n",
    "vect = CountVectorizer(max_features=1000, binary=True)\n",
    "#vect.fit(X_train)\n",
    "#X_train_dtm = vect.transform(X_train)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a MultinomialNB model and Display the confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "25cf0eef-461b-4961-94db-fa274ad0f74d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8756137479541735"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "%time nb.fit(X_train_dtm, y_train)\n",
    "nb.score(X_train_dtm, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d9374279-53f8-4e50-99d6-2761740d09ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  0,  0, -1,  0,  0,  0, -1, -1,  0, -1, -1, -1,  0,  0, -1,\n",
       "       -1,  0,  0,  0,  0,  0,  0, -1, -1,  0, -1,  0,  0, -1,  0,  0, -1,\n",
       "        0, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  1, -1,  0, -1,  0,\n",
       "       -1,  0, -1,  0,  0,  0, -1, -1,  0,  0, -1,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0, -1, -1, -1, -1,  1, -1, -1,  0,  0,  0, -1,  1, -1,\n",
       "        0, -1, -1,  0,  0,  0,  0, -1, -1, -1, -1,  0,  0, -1, -1, -1,  0,\n",
       "        0,  0, -1,  0, -1, -1, -1, -1,  0, -1,  0,  0, -1,  0, -1,  0,  0,\n",
       "        0,  0,  0,  0,  0, -1,  0,  0, -1,  0, -1, -1, -1,  0, -1,  0,  0,\n",
       "       -1,  0, -1, -1,  0, -1, -1,  0, -1, -1,  0,  0, -1, -1, -1,  0,  0,\n",
       "       -1, -1, -1, -1, -1,  0, -1,  0,  0, -1,  0,  0, -1, -1,  0,  0, -1,\n",
       "       -1,  0, -1, -1, -1,  0, -1,  0, -1, -1, -1,  0, -1,  0, -1, -1,  0,\n",
       "        0, -1, -1,  0,  0,  0, -1,  0,  0,  0, -1, -1,  0,  0, -1, -1, -1,\n",
       "       -1,  0,  0,  0,  0,  0,  0,  0, -1,  0, -1, -1,  0, -1,  0, -1, -1,\n",
       "        0, -1, -1,  0, -1,  0, -1,  0,  0, -1,  0,  0, -1,  0,  0,  0, -1,\n",
       "       -1, -1,  0,  1,  0, -1, -1, -1,  0,  0,  0,  0, -1, -1,  0, -1,  0,\n",
       "       -1, -1, -1,  0,  0, -1, -1, -1,  0, -1, -1, -1,  0,  0,  0, -1,  0,\n",
       "       -1,  0, -1, -1,  0, -1, -1, -1,  1, -1, -1, -1,  1,  0, -1,  0,  0,\n",
       "        0,  0,  0, -1, -1,  0, -1,  0,  0, -1, -1, -1, -1,  0, -1,  0,  0,\n",
       "        0,  0, -1,  0,  0,  0, -1,  0, -1, -1, -1, -1,  0, -1,  0, -1,  0,\n",
       "        0, -1, -1,  0,  0, -1, -1,  0,  0, -1,  0, -1,  0,  0,  0,  0,  1,\n",
       "       -1,  0,  0,  0, -1, -1, -1, -1,  0,  0,  0,  0, -1, -1, -1, -1,  0,\n",
       "        0,  0, -1,  0, -1,  1, -1,  0,  0, -1, -1, -1,  0, -1,  0, -1, -1,\n",
       "        0, -1,  0,  0, -1,  0, -1,  0,  0, -1,  0,  0, -1, -1,  0,  0, -1,\n",
       "       -1,  0, -1,  1,  0, -1, -1,  0,  0,  1, -1,  0,  0,  1,  0, -1,  1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dtm = vect.transform(X_test)\n",
    "y_pred = nb.predict(X_test_dtm)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cb6bebaf-0b5b-462b-b3b4-ac46c98f92f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.88%\n",
      "\n",
      "COnfusion Matrix:\n",
      " [[142   8   0]\n",
      " [ 44 176   0]\n",
      " [ 10  16  12]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "\n",
    "print(\"\\nCOnfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the POS tagging on the first 4 rows of ‘Review’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chandu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [(wow, NN), (yall, NN), (needa, JJ), (step, NN), (it, PRP), (up, RP), (apple, NN), (rt, NN), (heynyla, NN), (music, NN), (and, CC), (snapchat, NN), (at, IN), (the, DT), (same, JJ), (damn, NN), (time, NN), (thank, NN), (you, PRP), (note4, VBP)]\n",
      "1    [(what, WP), (happened, VBD), (to, TO), (apple, NN), (inc, NN), (httptcofjexi3op0u, NN), (aapl, NN), (apple, NN), (moneypress, NN), (httptcowxkmmtmarw, NN)]                                                                                       \n",
      "2    [(thank, NN), (u, JJ), (apple, NN), (i, NN), (can, MD), (now, RB), (compile, VB), (all, DT), (of, IN), (the, DT), (pics, NNS), (that, IN), (i, JJ), (communicate, VBP), (with, IN), (in, IN), (one, CD), (place, NN), (httptcotq1lo09oya, NN)]     \n",
      "3    [(the, DT), (oddly, RB), (uplifting, JJ), (story, NN), (of, IN), (the, DT), (apple, NN), (cofounder, NN), (who, WP), (sold, VBD), (his, PRP$), (stake, NN), (for, IN), (800, CD), (aapl, JJ), (aapl, NN), (httptcocizbvr05pj, NN)]                 \n",
      "Name: Pos_tag_Data, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "def applyPosTagging(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tag = nltk.pos_tag(tokens)\n",
    "    return tag\n",
    "\n",
    "pandas_df['Pos_tag_Data'] =  pandas_df['review'].apply(applyPosTagging)\n",
    "\n",
    "print(pandas_df['Pos_tag_Data'].head(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and display a dependency parser tree for the sentence:\n",
    "\n",
    "#He is one of the five black brothers who sit in judgment of Jon Snow for his actions during his time with the wildlings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   one                                                          \n",
      "  __________________________________|_____                                                       \n",
      " |   |   |                             brothers                                                 \n",
      " |   |   |    ____________________________|_______________                                       \n",
      " |   |   |   |   |   |     |                             sit                                    \n",
      " |   |   |   |   |   |     |     _________________________|_________                             \n",
      " |   |   |   |   |   |     |    |         |                      actions                        \n",
      " |   |   |   |   |   |     |    |         |                _________|_____                       \n",
      " |   |   |   |   |   |     |    |      judgment           |   |          time                   \n",
      " |   |   |   |   |   |     |    |    _____|______         |   |      _____|____________          \n",
      " |   |   |   |   |   |     |    |   |           Snow      |   |     |     |        wildlings    \n",
      " |   |   |   |   |   |     |    |   |      ______|____    |   |     |     |     _______|______   \n",
      " He  is  .   of the five black who  in    of         Jon for his  during his  with           the\n",
      "\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "server.start()\n",
    "dep_parser = CoreNLPDependencyParser(url=\"http://localhost:9000\")\n",
    "#dep_parser = CoreNLPDependencyParser()\n",
    "sent = \"He is one of the five black brothers who sit in judgment of Jon Snow for his actions during his time with the wildlings.\".split()\n",
    "parses = list(dep_parser.parse(sent))\n",
    "parses[0].tree().pretty_print()\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "NLPAssignment",
   "notebookOrigID": 2031168029084104,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
